{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dmZgPHzGY6b",
        "outputId": "bc01da93-f286-4d01-9bd3-90979821f4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget -q https://raw.githubusercontent.com/ml-compling-2022-hse/ml-intro/main/class2/IMDB-Movie-Data.csv\n",
        "!pip3 -q install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMqiLkXZJGap",
        "outputId": "50812abd-837e-4271-b1c1-ba9348bc8556"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# импорты необходимых библиотек\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "\n",
        "# import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from string import punctuation\n",
        "from typing import Callable"
      ],
      "metadata": {
        "id": "PLCJrECVGbFM"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('IMDB-Movie-Data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl28kG5QGjsJ",
        "outputId": "49878ef1-e5b5-44c2-b9d8-98fbaf7022fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(838, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sum(data['Metascore'].isna() + data['Revenue (Millions)'].isna())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpUTf0HNG94M",
        "outputId": "27e99969-e429-40ee-efab-ad877fdf0db7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "162"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.dropna()"
      ],
      "metadata": {
        "id": "6nNHvDKgHQj9"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = WordNetLemmatizer()\n",
        "stops = stopwords.words('english')"
      ],
      "metadata": {
        "id": "Qz1MOc7HICfc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateReg(data: pd.DataFrame, lemmatize: Callable,\n",
        "                regressor: Callable = Ridge, par: float = 1) -> None:\n",
        "    data['text'] = data.Description.apply(lemmatize)\n",
        "    input_text = list(data.lemma.values)\n",
        "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(input_text)]\n",
        "    model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)\n",
        "    vectors = []\n",
        "    for x in documents:\n",
        "        vec = list(model[x.tags][0])\n",
        "        vectors.append(vec)\n",
        "    split_df = pd.DataFrame(vectors,\n",
        "                        columns=['v1', 'v2', 'v3','v4',\"v5\"])\n",
        "\n",
        "    result = data.join(split_df, how='left')\n",
        "    data_sm = result[['Runtime (Minutes)',\"Year\",\n",
        "                'Rating', 'Votes',\n",
        "                'Revenue (Millions)','Metascore',\"v1\",\"v2\",\"v3\",\"v4\",\"v5\"]\n",
        "              ]\n",
        "    data_sm = data_sm.dropna()\n",
        "\n",
        "    X = data_sm.drop([\"Rating\"],axis=1).values \n",
        "    y = data_sm['Rating'].values\n",
        "\n",
        "    sc = StandardScaler()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(sc.fit_transform(X),\n",
        "                                                        y, random_state=42)\n",
        "    regressor = regressor(par) \n",
        "\n",
        "    regressor.fit(X_train, y_train)\n",
        "    y_preds = regressor.predict(X_test)\n",
        "    print(mean_absolute_error(y_test, y_preds))\n",
        "    print(mean_squared_error(y_test, y_preds))"
      ],
      "metadata": {
        "id": "dYN7R8_KJFp1"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: x.lower().split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHmTIaZ8Mc0E",
        "outputId": "edc001e1-39dc-4195-aaf7-bbc5e425a1f1"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4228922602440821\n",
            "0.3341609313662102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: word_tokenize(x.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPCBlvrQNisk",
        "outputId": "3f50fc3f-46fc-4256-a378-cc2973bc1ccd"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.42290358676569445\n",
            "0.3341647263289313\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmqyH9YqMP1D",
        "outputId": "57b084e1-6de4-45b6-c723-bc0bd449bbfa"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4228345299128619\n",
            "0.3340934012201121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После лемматизации с удалением стоп-слов и нормальной токенизацией ничего особенно не поменялось. А жаль."
      ],
      "metadata": {
        "id": "ARqlN9cSMq73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ],\n",
        "            0)\n",
        "\n",
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ],\n",
        "            2)\n",
        "\n",
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ],\n",
        "            3)\n",
        "\n",
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ],\n",
        "            4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eJFPS9bMv_g",
        "outputId": "2155aab6-2071-4994-d3a1-4d7181d7636f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.42283660376232546\n",
            "0.33421041119834966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4229093013433594\n",
            "0.33407104766730406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4229544087459793\n",
            "0.3340518927182101\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4229514577825\n",
            "0.3339426846302254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После мены коэффициента регуляризации -- тоже."
      ],
      "metadata": {
        "id": "otwmatKSN1ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: [\n",
        "                m.lemmatize(y.strip(punctuation))\n",
        "                for y in word_tokenize(x.lower()) if y not in stops\n",
        "                ],\n",
        "            Lasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IH7_JE4N6EK",
        "outputId": "8eb48fc9-19ae-452d-b523-ec19192838a3"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7520536127593316\n",
            "0.8563704428453197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лассо гораздо лучше справляется с задачей."
      ],
      "metadata": {
        "id": "poEKyJzxOMtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluateReg(data,\n",
        "            lambda x: word_tokenize(x.lower()),\n",
        "            Lasso)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ4vyy3JORQ-",
        "outputId": "68058cdc-6aed-4d10-b03e-f8a7493d6e83"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n",
            "WARNING:gensim.models.base_any2vec:under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7520536127593316\n",
            "0.8563704428453197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Хотя на нормальную токенизацию ему тоже всё равно."
      ],
      "metadata": {
        "id": "3W2akLOHOUCo"
      }
    }
  ]
}